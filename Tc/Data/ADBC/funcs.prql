# PRQL function definitions for tv
# use std.count to avoid ambiguity with column named 'count'

let freq = func c tbl <relation> -> (
  from tbl
  group {c} (aggregate {Cnt = std.count this})
  derive {Pct = Cnt * 100 / std.sum Cnt, Bar = s"repeat('#', CAST({Pct}/5 AS INTEGER))"}
  sort {-Cnt}
)

let cnt = func tbl <relation> -> (from tbl | aggregate {n = std.count this})

# Count distinct groups for given columns
let cntdist = func cols tbl <relation> -> (from tbl | group cols (take 1) | aggregate {n = std.count this})

let uniq = func c tbl <relation> -> (from tbl | group {c} (take 1) | select {c})

let stats = func c tbl <relation> -> (
  from tbl
  aggregate {n = std.count this, min = std.min c, max = std.max c, avg = std.average c, std = std.stddev c}
)

let meta = func c tbl <relation> -> (
  from tbl
  aggregate {cnt = s"COUNT({c})", dist = std.count_distinct c, total = std.count this, min = std.min c, max = std.max c}
)

# Downsample time series: last value per second, filter zeros/nulls
let ds_time = func x y tbl <relation> -> (
  from tbl
  filter s"{y} IS NOT NULL AND CAST({y} AS VARCHAR) NOT IN ('0','0.0','0.000000')"
  derive {_sec = s"SUBSTRING(CAST({x} AS VARCHAR), 1, 8)"}
  group {_sec} (sort {s"{x} DESC"} | take 1)
  sort {_sec}
  select {_sec, y}
)

# Downsample time series with category
let ds_time_cat = func x y c tbl <relation> -> (
  from tbl
  filter s"{y} IS NOT NULL AND CAST({y} AS VARCHAR) NOT IN ('0','0.0','0.000000')"
  derive {_sec = s"SUBSTRING(CAST({x} AS VARCHAR), 1, 8)"}
  group {_sec, c} (sort {s"{x} DESC"} | take 1)
  sort {_sec}
  select {_sec, y, c}
)

# Downsample time series with parameterized truncation length
let ds_trunc = func x y len tbl <relation> -> (
  from tbl
  filter s"{y} IS NOT NULL AND CAST({y} AS VARCHAR) NOT IN ('0','0.0','0.000000')"
  derive {_sec = s"SUBSTRING(CAST({x} AS VARCHAR), 1, {len})"}
  group {_sec} (sort {s"{x} DESC"} | take 1)
  sort {_sec}
  select {_sec, y}
)

# Downsample time series with category and parameterized truncation
let ds_trunc_cat = func x y c len tbl <relation> -> (
  from tbl
  filter s"{y} IS NOT NULL AND CAST({y} AS VARCHAR) NOT IN ('0','0.0','0.000000')"
  derive {_sec = s"SUBSTRING(CAST({x} AS VARCHAR), 1, {len})"}
  group {_sec, c} (sort {s"{x} DESC"} | take 1)
  sort {_sec}
  select {_sec, y, c}
)

# Downsample by sampling every Nth row, filter zeros/nulls
# Note: no final select â€” PRQL miscompiles select after filter on derived column.
# Extra _rn column in output is harmless (gnuplot uses 'using 1:2').
let ds_nth = func x y step tbl <relation> -> (
  from tbl
  select {x, y}
  filter s"{y} IS NOT NULL AND CAST({y} AS VARCHAR) NOT IN ('0','0.0','0.000000')"
  derive {_rn = s"ROW_NUMBER() OVER ()"}
  filter s"(_rn - 1) % {step} = 0"
)

# Downsample by sampling with category
let ds_nth_cat = func x y c step tbl <relation> -> (
  from tbl
  select {x, y, c}
  filter s"{y} IS NOT NULL AND CAST({y} AS VARCHAR) NOT IN ('0','0.0','0.000000')"
  derive {_rn = s"ROW_NUMBER() OVER ()"}
  filter s"(_rn - 1) % {step} = 0"
)

let colstat = func c nm tp tbl <relation> -> (
  from tbl
  aggregate {
    cnt = s"CAST(COUNT({c}) AS BIGINT)",
    dist = s"CAST(COUNT(DISTINCT {c}) AS BIGINT)",
    null_pct = s"CAST(ROUND((1.0 - COUNT({c})::FLOAT / NULLIF(COUNT(*),0)) * 100) AS BIGINT)",
    mn = s"CAST(MIN({c}) AS VARCHAR)",
    mx = s"CAST(MAX({c}) AS VARCHAR)"
  }
  derive {column = nm, coltype = tp}
  select {column, coltype, this.cnt, this.dist, null_pct, mn, mx}
)
